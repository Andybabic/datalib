{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dcef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "\n",
    "def getparrentpath():\n",
    "    return os.getcwd()\n",
    "\n",
    "\n",
    "# Get current working directory\n",
    "home= getparrentpath()\n",
    "\n",
    "\n",
    "# ini Pipeline\n",
    "current_dir = os.path.dirname(home)\n",
    "dataset_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(dataset_dir)\n",
    "sys.path.insert(0, dataset_dir)\n",
    "\n",
    "\n",
    "#import _0003_Code._0001_Modules._001_Main.master  as main\n",
    "#import _0003_Code._0001_Modules._002_Social_Media_Crawler.master  as crawler\n",
    "#import _0003_Code._0001_Modules._.....\n",
    "\n",
    "\n",
    "from _0003_Code._0001_Modules._001_Main import master as main\n",
    "from _0003_Code._0001_Modules._002_Social_Media_Crawler import master as crawler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa1f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: project_path : /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template\n",
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: settings_path : /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/settings.json\n",
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: project_name : Dataset_000_Template\n",
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: output_dir : /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/.output\n",
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: temp_folder : /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/.output\n",
      "[04-12 12:26:49] p426021 {/home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0003_Code/_0001_Modules/_001_Main/master/submodul/globalSettings.py:53} INFO - Updated Settings: result : /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/.output/results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project: /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template\n",
      "Project created: /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template\n",
      "init MasterModule done\n",
      "file  is created\n",
      "path: /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/.output\n",
      "file  is created\n",
      "path: /home/projectdrive/nextcloud/p_2021_counterspeech/0001_P_CounterStrike/_0002_Datasets/Dataset_000_Template/.output/results\n"
     ]
    }
   ],
   "source": [
    "#ini Modules in vars\n",
    "master=main.Master(home)\n",
    "crawler=crawler.Modul(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ini Model in modelBert Var\n",
    "modelBert = master.getModels('_0001_Model_Bert')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41791f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_of_the_file = 'Hate_Counter_Dataset.csv'\n",
    "dataset= master.setDataset(master.project.original_data_path,name_of_the_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "print(dataset.getSample())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filter by column ['Hate_IDs']['Counter_IDs']\n",
    "#dataset_HateID= dataset.getValue('Hate_IDs')\n",
    "#dataset_Counter= dataset.getValue('Counter_IDs')\n",
    "\n",
    "#get filter by rows [id][Text]['CounterSpeech'= True / False]\n",
    "#dataset_HateID= dataset.getRows('CounterSpeech', False)\n",
    "#dataset_Counter= dataset.getRows('CounterSpeech', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sample if you need a crawler ( ec. Twitter )\n",
    "\n",
    "#ini crawler:\n",
    "\n",
    "#consumer_key = ''\n",
    "#consumer_key_secret = ''\n",
    "#access_token = '-'\n",
    "#access_token_secret = ''\n",
    "#twittercrawler= crawler.createTwitterCrawler(consumer_key, consumer_key_secret, access_token, access_token_secret)\n",
    "\n",
    "#or Youtube\n",
    "\n",
    "\n",
    "developerKey=''\n",
    "\n",
    "\n",
    "#twittercrawler= master.createTwitterCrawler(consumer_key, consumer_key_secret, access_token, access_token_secret)\n",
    "#youtubecrawler= crawler.createYoutubeCrawler('')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Crawling by Lists for Tweeter\n",
    "\n",
    "#crawled_dataset_Hate=twittercrawler.crawlList(dataset_HateID)\n",
    "#crawled_dataset_Counter=twittercrawler.crawlList(dataset_Counter)\n",
    "\n",
    "#Start Crawling by Lists for Youtube\n",
    "\n",
    "#crawled_dataset_Hate=youtubecrawler.crawlList(dataset_HateID,True)\n",
    "#crawled_dataset_Counter=youtubecrawler.crawlList(dataset_Counter,True)\n",
    "\n",
    "\n",
    "\n",
    "#dataset.getSample(crawled_dataset_Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final List \n",
    "\n",
    "\n",
    "wanted= ['id', 'text']\n",
    "reduced_cleanDataset_Hate= dataset.reduce( crawled_dataset_Hate,wanted )\n",
    "reduced_cleanDataset_Counter= dataset.reduce( crawled_dataset_Counter,wanted )\n",
    "\n",
    "addedClass_cleanDataset_Hate= dataset.add( reduced_cleanDataset_Hate, 'Class', 0)\n",
    "addedClass_cleanDataset_Counter= dataset.add( reduced_cleanDataset_Counter, 'Class', 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge individual List to a single one ( input must be a List of Lists)\n",
    "cleanDataset= dataset.merge( [addedClass_cleanDataset_Hate,addedClass_cleanDataset_Counter] )\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60936d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2string(list):\n",
    "    string=''\n",
    "    for i in list:\n",
    "        string+=i\n",
    "    return string\n",
    "\n",
    "#take a list of data and remove all chars between \"@\" and first ' ' from Strings\n",
    "def remove_at(data):\n",
    "        char_list=[]\n",
    "        char_count= 0\n",
    "        \n",
    "        string_text= data['text']\n",
    "        for i in string_text:   \n",
    "            if len(char_list) >= 1:\n",
    "                if i  == ' ':\n",
    "                    string_text= string_text.replace(list2string(char_list),' ')\n",
    "                    char_list=[]\n",
    "                else :\n",
    "                    char_list.append(i)\n",
    "            if i == '@':\n",
    "                char_list.append(i)\n",
    "        data['text']= string_text\n",
    "        return data\n",
    "            \n",
    "             \n",
    "\n",
    "def Searchall(data,func):\n",
    "    for listitem in data:\n",
    "        if type(listitem) == type(list()):\n",
    "            Searchall(listitem,func)\n",
    "        else: \n",
    "            data[0]=func(data[0])\n",
    "            \n",
    "\n",
    "\n",
    "#cleanDataset=remove_at(cleanDataset)\n",
    "\n",
    "Searchall(cleanDataset,remove_at)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3841a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate Final List after Splittin in 003_clean_dataset\n",
    "\n",
    "finalDataset= master.splitDataset(cleanDataset,70,20)\n",
    "\n",
    "head=['ID','Text','Class']\n",
    "dataset.saveArrayOfDictionariesAsTSV(cleanDataset, 'clean_dataset.tsv', path=master.project.clean_dataset_path,customhead=head)\n",
    "dataset.saveArrayOfDictionariesAsTSV(finalDataset.test, 'test.tsv', path=master.project.clean_dataset_path,customhead=head)\n",
    "dataset.saveArrayOfDictionariesAsTSV(finalDataset.train, 'train.tsv', path=master.project.clean_dataset_path,customhead=head)\n",
    "dataset.saveArrayOfDictionariesAsTSV(finalDataset.val, 'val.tsv', path=master.project.clean_dataset_path,customhead=head)\n",
    "                                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start Bert \n",
    "\n",
    "modelBert.process_start()\n",
    "\n",
    "#Bert is running in its own Space , so we must waiting \n",
    "modelBert.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return False ( there will be never blocked GPUs anymore)\n",
    "print(modelBert.process.is_alive())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything is done an all relevant Data are in /_0004_Evaluation/_002_Runs/.. Directories\n",
    "master.close(os.path.join(home,'dataset_start.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990de63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a371d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d30924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0dc5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
